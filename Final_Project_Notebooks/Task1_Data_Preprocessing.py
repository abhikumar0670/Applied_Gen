{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Task 1: Load and preprocess the League of Legends dataset"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Shared setup: load LeagueofLegends.csv if present, otherwise create a small synthetic dataset\nimport os, pandas as pd, numpy as np, torch\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nDATA_CSV = \"LeagueofLegends.csv\"\n\nif os.path.exists(DATA_CSV):\n    df = pd.read_csv(DATA_CSV)\n    print(\"Loaded dataset from\", DATA_CSV, \"shape=\", df.shape)\nelse:\n    print(\"Warning: LeagueofLegends.csv not found. Creating a small synthetic dataset for demonstration.\")\n    # Create synthetic dataset: 500 samples, 10 numeric features, binary target 'blueWins'\n    np.random.seed(42)\n    n = 500\n    features = {f\"feat_{i}\": np.random.randn(n) for i in range(10)}\n    df = pd.DataFrame(features)\n    # A simple linear combination + noise determines target\n    logits = df.values.dot(np.arange(1,11)) * 0.01\n    probs = 1 / (1 + np.exp(-logits))\n    df['blueWins'] = (probs + 0.1*np.random.rand(n) > 0.5).astype(int)\n    df.to_csv(DATA_CSV, index=False)\n    print(\"Synthetic dataset saved to\", DATA_CSV, \"shape=\", df.shape)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "# Features/target split, train/test, scaling, torch tensors\nTARGET_COL = \"blueWins\"\nif TARGET_COL not in df.columns:\n    raise ValueError(\"Target column 'blueWins' not found in dataframe. Please adjust TARGET_COL.\")\n\nX = df.drop(columns=[TARGET_COL])\ny = df[TARGET_COL]\n\nprint(\"Features shape:\", X.shape)\nprint(\"Target distribution:\\n\", y.value_counts(normalize=True))\n\n# Train/test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n\n# Standardize\nscaler = StandardScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)\n\n# Convert to PyTorch tensors\nX_train_t = torch.tensor(X_train_scaled, dtype=torch.float32)\nX_test_t = torch.tensor(X_test_scaled, dtype=torch.float32)\ny_train_t = torch.tensor(y_train.values, dtype=torch.float32).view(-1,1)\ny_test_t = torch.tensor(y_test.values, dtype=torch.float32).view(-1,1)\n\nprint(\"X_train_t shape:\", X_train_t.shape)\nprint(\"y_train_t shape:\", y_train_t.shape)\n\n# Save objects for other notebooks to import if running in same folder\nimport joblib, numpy as np\njoblib.dump(scaler, \"scaler.save\")\nnp.save(\"X_train.npy\", X_train_scaled); np.save(\"X_test.npy\", X_test_scaled)\nnp.save(\"y_train.npy\", y_train.values); np.save(\"y_test.npy\", y_test.values)\nprint(\"Saved scaler and numpy arrays: scaler.save, X_train.npy, X_test.npy, y_train.npy, y_test.npy\")"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 5}