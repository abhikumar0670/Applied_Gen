{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Task 4: L2 regularization via optimizer weight_decay"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import numpy as np, torch\nif not os.path.exists(\"X_train.npy\"): raise FileNotFoundError(\"Run Task1 first.\")\nX_train = np.load(\"X_train.npy\"); X_test = np.load(\"X_test.npy\")\ny_train = np.load(\"y_train.npy\"); y_test = np.load(\"y_test.npy\")\nX_train_t = torch.tensor(X_train, dtype=torch.float32); X_test_t = torch.tensor(X_test, dtype=torch.float32)\ny_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1,1); y_test_t = torch.tensor(y_test, dtype=torch.float32).view(-1,1)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import torch.nn as nn, torch.optim as optim\nclass LogisticRegressionModel(nn.Module):\n    def __init__(self, input_dim):\n        super().__init__(); self.linear = nn.Linear(input_dim,1)\n    def forward(self,x): return torch.sigmoid(self.linear(x))\n\nmodel = LogisticRegressionModel(X_train_t.shape[1])\noptimizer = optim.SGD(model.parameters(), lr=0.01, weight_decay=1e-3)  # L2 regularization\ncriterion = nn.BCELoss()\n\nfrom torch.utils.data import TensorDataset, DataLoader\nloader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)\n\nfor epoch in range(1, 31):\n    model.train(); total=0.0\n    for xb, yb in loader:\n        optimizer.zero_grad()\n        out = model(xb); loss = criterion(out, yb)\n        loss.backward(); optimizer.step()\n        total += loss.item()*xb.size(0)\n    if epoch % 10 == 0 or epoch==1:\n        with torch.no_grad():\n            ta = (model(X_train_t)>=0.5).float().eq(y_train_t).float().mean().item()\n            te = (model(X_test_t)>=0.5).float().eq(y_test_t).float().mean().item()\n        print(f\"Epoch {epoch} TrainAcc {ta:.3f} TestAcc {te:.3f}\")"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 5}