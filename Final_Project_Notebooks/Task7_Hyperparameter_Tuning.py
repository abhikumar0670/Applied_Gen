{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Task 7: Hyperparameter tuning - find best learning rate"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import numpy as np, torch\nif not os.path.exists(\"X_train.npy\"): raise FileNotFoundError(\"Run Task1 first.\")\nX_train = np.load(\"X_train.npy\"); y_train = np.load(\"y_train.npy\")\nX_test = np.load(\"X_test.npy\"); y_test = np.load(\"y_test.npy\")\nX_train_t = torch.tensor(X_train, dtype=torch.float32); y_train_t = torch.tensor(y_train, dtype=torch.float32).view(-1,1)\nX_test_t = torch.tensor(X_test, dtype=torch.float32); y_test_t = torch.tensor(y_test, dtype=torch.float32).view(-1,1)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import torch.nn as nn, torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nlrs = [0.5, 0.1, 0.01, 0.001]\nbest = (None, -1)\nfor lr in lrs:\n    model = nn.Sequential(nn.Linear(X_train_t.shape[1],1), nn.Sigmoid())\n    opt = optim.SGD(model.parameters(), lr=lr)\n    loader = DataLoader(TensorDataset(X_train_t, y_train_t), batch_size=32, shuffle=True)\n    for epoch in range(20):\n        for xb, yb in loader:\n            opt.zero_grad(); out = model(xb); loss = nn.BCELoss()(out, yb); loss.backward(); opt.step()\n    with torch.no_grad():\n        acc = (model(X_test_t)>=0.5).float().eq(y_test_t).float().mean().item()\n    print(f\"lr={lr} test_acc={acc:.4f}\")\n    if acc > best[1]:\n        best = (lr, acc)\nprint(\"Best lr:\", best)"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}}, "nbformat": 4, "nbformat_minor": 5}