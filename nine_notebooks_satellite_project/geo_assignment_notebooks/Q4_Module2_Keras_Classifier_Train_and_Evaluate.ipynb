{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Module 2: Train and Evaluate a Keras-Based Classifier"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import os, glob, numpy as np, matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\n\nDATASET_DIR = \"./images_dataSAT\"\nDIR_NON_AGRI = os.path.join(DATASET_DIR, \"class_0_non_agri\")\nDIR_AGRI = os.path.join(DATASET_DIR, \"class_1_agri\")\n\ndef _ensure_dataset():\n    os.makedirs(DIR_NON_AGRI, exist_ok=True)\n    os.makedirs(DIR_AGRI, exist_ok=True)\n    if len(os.listdir(DIR_NON_AGRI))>0 and len(os.listdir(DIR_AGRI))>0:\n        return\n    import numpy as np\n    from PIL import Image, ImageDraw\n    rng = np.random.default_rng(0)\n    for cls_dir, pattern in [(DIR_NON_AGRI, 'rect'), (DIR_AGRI, 'lines')]:\n        for i in range(12):\n            img = Image.new(\"RGB\",(64,64),(rng.integers(20,235),rng.integers(20,235),rng.integers(20,235)))\n            d = ImageDraw.Draw(img)\n            if pattern=='rect':\n                d.rectangle([10,10,54,54], outline=(255,255,255), width=2)\n            else:\n                for y in range(5,64,10):\n                    d.line([0,y,64,y], fill=(255,255,255), width=1)\n            img.save(os.path.join(cls_dir, f\"img_{{i:03d}}.png\"))\n\n# Copy dataset from /mnt/data if available\nif os.path.exists('/mnt/data/images_dataSAT'):\n    import shutil\n    if not os.path.exists(DATASET_DIR):\n        shutil.copytree('/mnt/data/images_dataSAT', DATASET_DIR)\n_ensure_dataset()\nprint(\"Dataset ready at\", os.path.abspath(DATASET_DIR))"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import os, matplotlib.pyplot as plt, tensorflow as tf\nfrom tensorflow.keras import layers, models\n\ndataset_path = DATASET_DIR\nfnames = []\nfor root, dirs, files in os.walk(dataset_path):\n    for f in files:\n        if f.lower().endswith(('.png','.jpg','.jpeg')):\n            fnames.append(os.path.join(root, f))\nfnames = sorted(fnames)\nprint(\"Total files found:\", len(fnames)); print(\"First 5:\", fnames[:5])\n\nval_ds = tf.keras.utils.image_dataset_from_directory(dataset_path, image_size=(64,64), batch_size=16, validation_split=0.3, subset='validation', seed=123)\ntrain_ds = tf.keras.utils.image_dataset_from_directory(dataset_path, image_size=(64,64), batch_size=16, validation_split=0.3, subset='training', seed=123)\nval_ds = val_ds.prefetch(tf.data.AUTOTUNE); train_ds = train_ds.prefetch(tf.data.AUTOTUNE)\n\ntest_model = models.Sequential([\n    layers.Rescaling(1./255, input_shape=(64,64,3)),\n    layers.Conv2D(16, 3, activation='relu'), layers.MaxPooling2D(),\n    layers.Conv2D(32, 3, activation='relu'), layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, activation='relu'), layers.MaxPooling2D(),\n    layers.Conv2D(64, 3, activation='relu'), layers.MaxPooling2D(),\n    layers.Flatten(),\n    layers.Dense(128, activation='relu'),\n    layers.Dense(64, activation='relu'),\n    layers.Dense(32, activation='relu'),\n    layers.Dense(16, activation='relu'),\n    layers.Dense(1, activation='sigmoid')\n])\nprint(\"Total layers:\", len(test_model.layers))\nckpt = tf.keras.callbacks.ModelCheckpoint(\"best.keras\", monitor=\"val_accuracy\", save_best_only=True, mode=\"max\")\ntest_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nhist = test_model.fit(train_ds, validation_data=val_ds, epochs=3, callbacks=[ckpt])\nplt.figure(); plt.plot(hist.history['loss'], label='train_loss'); plt.plot(hist.history['val_loss'], label='val_loss'); plt.legend(); plt.title('Loss'); plt.show()"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}