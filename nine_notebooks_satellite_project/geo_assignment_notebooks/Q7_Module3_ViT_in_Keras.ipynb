{"cells": [{"cell_type": "markdown", "metadata": {}, "source": "# Module 3: Vision Transformers in Keras (Hybrid CNN + ViT)"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import os, glob, numpy as np, matplotlib.pyplot as plt\nfrom PIL import Image, ImageDraw\n\nDATASET_DIR = \"./images_dataSAT\"\nDIR_NON_AGRI = os.path.join(DATASET_DIR, \"class_0_non_agri\")\nDIR_AGRI = os.path.join(DATASET_DIR, \"class_1_agri\")\n\ndef _ensure_dataset():\n    os.makedirs(DIR_NON_AGRI, exist_ok=True)\n    os.makedirs(DIR_AGRI, exist_ok=True)\n    if len(os.listdir(DIR_NON_AGRI))>0 and len(os.listdir(DIR_AGRI))>0:\n        return\n    import numpy as np\n    from PIL import Image, ImageDraw\n    rng = np.random.default_rng(0)\n    for cls_dir, pattern in [(DIR_NON_AGRI, 'rect'), (DIR_AGRI, 'lines')]:\n        for i in range(12):\n            img = Image.new(\"RGB\",(64,64),(rng.integers(20,235),rng.integers(20,235),rng.integers(20,235)))\n            d = ImageDraw.Draw(img)\n            if pattern=='rect':\n                d.rectangle([10,10,54,54], outline=(255,255,255), width=2)\n            else:\n                for y in range(5,64,10):\n                    d.line([0,y,64,y], fill=(255,255,255), width=1)\n            img.save(os.path.join(cls_dir, f\"img_{{i:03d}}.png\"))\n\n# Copy dataset from /mnt/data if available\nif os.path.exists('/mnt/data/images_dataSAT'):\n    import shutil\n    if not os.path.exists(DATASET_DIR):\n        shutil.copytree('/mnt/data/images_dataSAT', DATASET_DIR)\n_ensure_dataset()\nprint(\"Dataset ready at\", os.path.abspath(DATASET_DIR))"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": "import tensorflow as tf\nfrom tensorflow.keras import layers, models\n\ndef build_cnn():\n    inp = layers.Input((64,64,3))\n    x = layers.Rescaling(1./255)(inp)\n    x = layers.Conv2D(16,3,activation='relu', name='feature_conv')(x)\n    x = layers.MaxPooling2D()(x)\n    x = layers.Conv2D(32,3,activation='relu')(x)\n    x = layers.GlobalAveragePooling2D(name='gap')(x)\n    out = layers.Dense(1, activation='sigmoid')(x)\n    return models.Model(inp, out)\n\ntmp_path = \"cnn_base.keras\"\nif not tf.io.gfile.exists(tmp_path):\n    m = build_cnn(); m.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n    ds = tf.keras.utils.image_dataset_from_directory(DATASET_DIR, image_size=(64,64), batch_size=16, validation_split=0.3, subset='training', seed=123)\n    m.fit(ds, epochs=1, verbose=0); m.save(tmp_path)\n\ncnn_model = tf.keras.models.load_model(tmp_path)\ncnn_model.summary()\nfeature_layer_name = 'gap'\nprint(\"Feature layer used:\", feature_layer_name)\n\ndef build_cnn_vit_hybrid(cnn_backbone, feature_layer_name, projection_dim=64, transformer_layers=2, num_heads=2):\n    inp = layers.Input((64,64,3))\n    x = layers.Rescaling(1./255)(inp)\n    patch_size = 8\n    patches = tf.image.extract_patches(images=x, sizes=[1,patch_size,patch_size,1], strides=[1,patch_size,patch_size,1], rates=[1,1,1,1], padding='VALID')\n    patches = layers.Reshape((-1, patch_size*patch_size*3))(patches)\n    encoded = layers.Dense(projection_dim)(patches)\n    positions = tf.range(start=0, limit=tf.shape(encoded)[1], delta=1)\n    pos_embed = layers.Embedding(input_dim=100, output_dim=projection_dim)(positions)\n    encoded += pos_embed\n    for _ in range(transformer_layers):\n        attn_out = layers.MultiHeadAttention(num_heads=num_heads, key_dim=projection_dim)(encoded, encoded)\n        x2 = layers.Add()([encoded, attn_out]); x2 = layers.LayerNormalization()(x2)\n        mlp = layers.Dense(projection_dim*2, activation='gelu')(x2); mlp = layers.Dense(projection_dim)(mlp)\n        encoded = layers.Add()([x2, mlp]); encoded = layers.LayerNormalization()(encoded)\n    rep = layers.GlobalAveragePooling1D()(encoded)\n    out = layers.Dense(1, activation='sigmoid')(rep)\n    return models.Model(inp, out, name=\"cnn_vit_hybrid\")\n\nhybrid_model = build_cnn_vit_hybrid(cnn_model, feature_layer_name)\nhybrid_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nprint(\"Hybrid model compiled.\")"}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"file_extension": ".py", "mimetype": "text/x-python", "name": "python", "pygments_lexer": "ipython3"}}, "nbformat": 4, "nbformat_minor": 5}