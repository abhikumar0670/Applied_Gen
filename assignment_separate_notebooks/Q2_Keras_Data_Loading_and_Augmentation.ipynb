{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aed202b2",
   "metadata": {},
   "source": [
    "# Q2 â€” Data Loading & Augmentation Using Keras\n",
    "Creates `all_image_paths`, `temp`, `custom_data_generator` (batch size = 8), and a validation generator with batch size 8. Uses dummy folders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e929c84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, glob, numpy as np\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ensure dummy dataset exists (reuse from Q1)\n",
    "root = Path(\"images_dataSAT\")\n",
    "classes = ['class_0_non_agri','class_1_agri']\n",
    "\n",
    "all_image_paths = []\n",
    "all_labels = []\n",
    "for idx, cls in enumerate(classes):\n",
    "    p = root/cls\n",
    "    for f in sorted(p.glob('*')):\n",
    "        if f.suffix.lower() in {'.jpg','.jpeg','.png'}:\n",
    "            all_image_paths.append(str(f))\n",
    "            all_labels.append(idx)\n",
    "\n",
    "print('Total images found:', len(all_image_paths))\n",
    "\n",
    "# temp: zip paths and labels and show sample\n",
    "temp = list(zip(all_image_paths, all_labels))\n",
    "print('\\nFirst 6 entries in temp:')\n",
    "for it in temp[:6]:\n",
    "    print(it)\n",
    "\n",
    "# custom_data_generator yielding batches of size 8\n",
    "def load_img_array(path, target_size=(64,64)):\n",
    "    img = Image.open(path).convert('RGB').resize(target_size)\n",
    "    return np.array(img)/255.0\n",
    "\n",
    "def custom_data_generator(paths, labels, batch_size=8, shuffle=True):\n",
    "    idxs = np.arange(len(paths))\n",
    "    while True:\n",
    "        if shuffle:\n",
    "            np.random.shuffle(idxs)\n",
    "        for start in range(0, len(paths), batch_size):\n",
    "            batch_idx = idxs[start:start+batch_size]\n",
    "            X = [load_img_array(paths[i]) for i in batch_idx]\n",
    "            y = [labels[i] for i in batch_idx]\n",
    "            yield np.stack(X), tf.keras.utils.to_categorical(y, num_classes=2)\n",
    "\n",
    "# show one batch of size 8\n",
    "gen = custom_data_generator(all_image_paths, all_labels, batch_size=8)\n",
    "Xb, yb = next(gen)\n",
    "print('\\nCustom batch shapes:', Xb.shape, yb.shape)\n",
    "\n",
    "# validation generator with batch size 8 using ImageDataGenerator\n",
    "datagen = ImageDataGenerator(rescale=1./255, validation_split=0.2)\n",
    "val_gen = datagen.flow_from_directory(str(root), target_size=(64,64), batch_size=8, subset='validation', class_mode='categorical', shuffle=False)\n",
    "Xv, yv = next(val_gen)\n",
    "print('Validation batch shapes (batch_size=8):', Xv.shape, yv.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
