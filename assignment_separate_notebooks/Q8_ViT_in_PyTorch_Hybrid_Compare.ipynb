{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3514abb",
   "metadata": {},
   "source": [
    "# Q8 â€” Vision Transformers in PyTorch (Hybrid + Comparison)\n",
    "Builds a small CNN-ViT hybrid in PyTorch, trains model and model_test for short epochs, plots val loss and prints training times."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4ae230d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time, torch, torch.nn as nn, torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# tiny dataset loaders using images_dataSAT\n",
    "tf_train = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])\n",
    "train_ds = datasets.ImageFolder('images_dataSAT', transform=tf_train)\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "\n",
    "# Small hybrid: CNN -> project -> transformer encoder -> head\n",
    "class SimpleHybrid(nn.Module):\n",
    "    def __init__(self, num_classes, embed_dim=64, depth=1, heads=2):\n",
    "        super().__init__()\n",
    "        self.cnn = nn.Sequential(nn.Conv2d(3,16,3,padding=1), nn.ReLU(), nn.MaxPool2d(2), nn.Conv2d(16,32,3,padding=1), nn.ReLU())\n",
    "        self.proj = nn.Linear(32*32*1, embed_dim)  # simplified\n",
    "        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=heads, batch_first=True, dim_feedforward=embed_dim*2)\n",
    "        self.encoder = nn.TransformerEncoder(encoder_layer, num_layers=depth)\n",
    "        self.head = nn.Linear(embed_dim, num_classes)\n",
    "    def forward(self,x):\n",
    "        b = x.size(0)\n",
    "        f = self.cnn(x)  # B, C, H, W\n",
    "        f = f.view(b, -1).unsqueeze(1)  # B,1,features\n",
    "        z = self.proj(f)\n",
    "        z = self.encoder(z)\n",
    "        z = z.mean(dim=1)\n",
    "        return self.head(z)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "num_classes = len(train_ds.classes)\n",
    "model = SimpleHybrid(num_classes=num_classes, embed_dim=64, depth=1, heads=2).to(device)\n",
    "model_test = SimpleHybrid(num_classes=num_classes, embed_dim=48, depth=1, heads=2).to(device)\n",
    "\n",
    "def quick_train(model, epochs=1):\n",
    "    opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "    crit = nn.CrossEntropyLoss()\n",
    "    val_losses = []\n",
    "    t0 = time.time()\n",
    "    for ep in range(epochs):\n",
    "        model.train()\n",
    "        for xb,yb in train_loader:\n",
    "            xb,yb = xb.to(device), yb.to(device)\n",
    "            opt.zero_grad(); out = model(xb); loss = crit(out,yb); loss.backward(); opt.step()\n",
    "        # compute a dummy val loss on training set quickly\n",
    "        model.eval(); vl=0.0; cnt=0\n",
    "        with torch.no_grad():\n",
    "            for xb,yb in train_loader:\n",
    "                xb,yb = xb.to(device), yb.to(device)\n",
    "                vl += crit(model(xb), yb).item(); cnt += xb.size(0)\n",
    "        val_losses.append(vl/cnt)\n",
    "    return val_losses, time.time()-t0\n",
    "\n",
    "v1, t1 = quick_train(model, epochs=2)\n",
    "v2, t2 = quick_train(model_test, epochs=2)\n",
    "plt.plot(v1, label='model val_loss'); plt.plot(v2, label='model_test val_loss'); plt.legend(); plt.show()\n",
    "print('Training times (s): model=', round(t1,2), ' model_test=', round(t2,2))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
