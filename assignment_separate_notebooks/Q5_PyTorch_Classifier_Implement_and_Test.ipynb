{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6ebf5004",
   "metadata": {},
   "source": [
    "# Q5 â€” Implement & Test PyTorch-Based Classifier\n",
    "Includes short answer placeholders (random init, tqdm, torch.no_grad, resetting metrics), transforms, val_loader, plotting loss, and extracting preds/labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4267ce99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Short answers (fill these when submitting)\n",
    "print('Q5 Theory placeholders:') \n",
    "print('- Why random init: ensures symmetry breaking between neurons so learning can occur.')\n",
    "print('- tqdm: progress bar utility for loops.')\n",
    "print('- Reset metrics each epoch: to avoid accumulating across epochs and get per-epoch metrics.')\n",
    "print('- torch.no_grad(): avoids tracking gradients during eval to save memory/time.')\n",
    "print('- Evaluation metrics: accuracy, precision, recall, F1, confusion matrix.')\n",
    "\n",
    "# Implement pipeline\n",
    "import torch, torch.nn as nn, torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "tf_train = transforms.Compose([transforms.Resize((64,64)), transforms.RandomHorizontalFlip(), transforms.ToTensor()])\n",
    "tf_val = transforms.Compose([transforms.Resize((64,64)), transforms.ToTensor()])\n",
    "\n",
    "train_ds = datasets.ImageFolder('images_dataSAT', transform=tf_train)\n",
    "val_ds = datasets.ImageFolder('images_dataSAT', transform=tf_val)\n",
    "\n",
    "train_loader = DataLoader(train_ds, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_ds, batch_size=4, shuffle=False)\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Conv2d(3,16,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.Conv2d(16,32,3,padding=1), nn.ReLU(), nn.MaxPool2d(2),\n",
    "            nn.AdaptiveAvgPool2d((1,1))\n",
    "        )\n",
    "        self.fc = nn.Linear(32, num_classes)\n",
    "    def forward(self,x):\n",
    "        x = self.net(x).view(x.size(0), -1)\n",
    "        return self.fc(x)\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = Net(num_classes=len(train_ds.classes)).to(device)\n",
    "opt = optim.Adam(model.parameters(), lr=1e-3)\n",
    "crit = nn.CrossEntropyLoss()\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "for epoch in range(3):\n",
    "    model.train()\n",
    "    running = 0.0\n",
    "    for xb, yb in train_loader:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        opt.zero_grad()\n",
    "        out = model(xb)\n",
    "        loss = crit(out, yb)\n",
    "        loss.backward()\n",
    "        opt.step()\n",
    "        running += loss.item()*xb.size(0)\n",
    "    train_losses.append(running/len(train_loader.dataset))\n",
    "    # validation\n",
    "    model.eval()\n",
    "    vr = 0.0\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in val_loader:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            out = model(xb)\n",
    "            loss = crit(out, yb)\n",
    "            vr += loss.item()*xb.size(0)\n",
    "    val_losses.append(vr/len(val_loader.dataset))\n",
    "    print(f'Epoch {epoch+1}: train_loss={train_losses[-1]:.4f}, val_loss={val_losses[-1]:.4f}')\n",
    "\n",
    "# plot loss\n",
    "plt.plot(train_losses, label='train_loss'); plt.plot(val_losses, label='val_loss'); plt.legend(); plt.show()\n",
    "\n",
    "# extract predictions & labels\n",
    "all_preds, all_labels = [], []\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    for xb, yb in val_loader:\n",
    "        xb = xb.to(device)\n",
    "        logits = model(xb)\n",
    "        preds = logits.argmax(dim=1).cpu().numpy()\n",
    "        all_preds.extend(preds.tolist())\n",
    "        all_labels.extend(yb.numpy().tolist())\n",
    "\n",
    "print('Confusion matrix:\\n', confusion_matrix(all_labels, all_preds))\n",
    "print(classification_report(all_labels, all_preds, zero_division=0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
