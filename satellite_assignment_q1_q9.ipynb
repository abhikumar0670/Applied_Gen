
{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Satellite Image Classification Assignment (Q1–Q9)\n",
    "This notebook contains solutions for all 9 questions in the assignment. \n",
    "Dummy image data is used so you can run this anywhere; replace with your actual dataset for final results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import seaborn as sns\n",
    "\n",
    "# Generate dummy images for portability\n",
    "os.makedirs('dummy_dataset/train/class1', exist_ok=True)\n",
    "os.makedirs('dummy_dataset/train/class2', exist_ok=True)\n",
    "os.makedirs('dummy_dataset/validation/class1', exist_ok=True)\n",
    "os.makedirs('dummy_dataset/validation/class2', exist_ok=True)\n",
    "\n",
    "from PIL import Image\n",
    "for folder in ['dummy_dataset/train/class1', 'dummy_dataset/train/class2', 'dummy_dataset/validation/class1', 'dummy_dataset/validation/class2']:\n",
    "    for i in range(5):\n",
    "        img = Image.fromarray(np.uint8(np.random.rand(64,64,3)*255))\n",
    "        img.save(f'{folder}/img_{i}.jpg')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q1 – Count Images in Each Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk('dummy_dataset'):\n",
    "    print(f\"{root}: {len([f for f in files if f.endswith('.jpg')])} images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q2 – Data Augmentation Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(rotation_range=40, width_shift_range=0.2,\n",
    "                             height_shift_range=0.2, shear_range=0.2,\n",
    "                             zoom_range=0.2, horizontal_flip=True, fill_mode='nearest')\n",
    "\n",
    "img = load_img('dummy_dataset/train/class1/img_0.jpg')\n",
    "x = img_to_array(img)\n",
    "x = x.reshape((1,) + x.shape)\n",
    "\n",
    "i = 0\n",
    "for batch in datagen.flow(x, batch_size=1):\n",
    "    plt.imshow(array_to_img(batch[0]))\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    i += 1\n",
    "    if i > 2:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q3 – CNN Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    Conv2D(32, (3,3), activation='relu', input_shape=(64,64,3)),\n",
    "    MaxPooling2D(2,2),\n",
    "    Conv2D(64, (3,3), activation='relu'),\n",
    "    MaxPooling2D(2,2),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.5),\n",
    "    Dense(2, activation='softmax')\n",
    "])\n",
    "model.compile(optimizer=Adam(), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4 – Data Generators for Training & Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255)\n",
    "val_gen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_data = train_gen.flow_from_directory('dummy_dataset/train', target_size=(64,64),\n",
    "                                           batch_size=2, class_mode='categorical')\n",
    "val_data = val_gen.flow_from_directory('dummy_dataset/validation', target_size=(64,64),\n",
    "                                       batch_size=2, class_mode='categorical')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5 – Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(train_data, validation_data=val_data, epochs=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q6 – Training Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['accuracy'], label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], label='val acc')\n",
    "plt.legend(); plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q7 – Predictions & Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_data.reset()\n",
    "preds = model.predict(val_data)\n",
    "y_pred = np.argmax(preds, axis=1)\n",
    "y_true = val_data.classes\n",
    "\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
    "plt.xlabel('Predicted'); plt.ylabel('True');\n",
    "plt.show()\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q8 – Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('satellite_model.h5')\n",
    "print('Model saved as satellite_model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q9 – Load and Use Saved Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "loaded_model = load_model('satellite_model.h5')\n",
    "print('Model loaded successfully')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.x"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
